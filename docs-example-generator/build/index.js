"use strict";
// const llm = makeOpenAiChatLlm({
//   openAiClient,
//   deployment: OPENAI_CHAT_COMPLETION_DEPLOYMENT,
//   systemPrompt,
//   openAiLmmConfigOptions: {
//     temperature: 0,
//     maxTokens: 500,
//   },
//   generateUserPrompt,
// });
